---
permalink: /
title: "Profile"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
 Hello, I'm Tengfei Li 👋 ( AKA. tfcoder ⌨️)
`23 y/o` | `Master of AI @ Sichuan University` | 📧 `tfcoder@qq.com` | 📱 `15516991101`

🌐 *Building the future of human-centric AI with multimodal intelligence*

---

## 🎯 Research Focus

My core research agenda centers on **human-centric artificial intelligence**, with specialized expertise in:

🕴️ **Human Pose Estimation**:  `3D Reconstruction`  `Occlusion Handling`   `MultiModel Methods`

💃 **Motion Synthesis & Generation**: `Interactive`  `Text-Driven Control`  `Long-Sequence Generation`

**👟Video Motion Capture System**:

---

## 🚀 Key Projects & Innovations

### 💃 **Self-Forcing Autoregressive Diffusion for Real-Time Text-Driven Motion Generation**

`AutoRegress Diffusion`  `DiT`   `Reinforcement Learning (PPO)`  `Real-time Control`
✅ **SOTA Performance**: Achieved 300+ FPS with KV Cache acceleration
✅ **Breakthrough**: Enabled continuous long-sequence generation via novel self-forcing paradigm
✅ **Optimized**: Balanced quality/speed via noise scheduling & annealing strategies

https://github.com/user-attachments/assets/f8614513-d844-493e-8da8-54cf536d6116

<video controls width='100%'>
  <source src="../assets/videos/MoGenRT_480p.mp4" type="video/mp4">
</video>

<video controls width='100%'>
  <source src="https://github.com/user-attachments/assets/f8614513-d844-493e-8da8-54cf536d6116" type="video/mp4">
</video>

<video controls width='100%'>
  <source src="https://github.com/LTF-coding/LTF-coding.github.io/blob/master/assets/videos/MoGenRT_480p.mp4" type="video/mp4">
</video>

<video controls width='100%'>
  <source src="https://LTF-coding.github.io/blob/master/assets/videos/MoGenRT_480p.mp4" type="video/mp4">
</video>


<iframe src="https://youtu.be/embed/x-4q5u8g0qA" frameborder="0"></iframe> 

### 🌐 **MetaPose: Multimodal Enhancement and Transformation Alignment 3D Pose Estimation**

`Vision-Text-Spatial Fusion`  `Cross-Modal Alignment` ` Occlusion Robustness`
✅ **IEEE TMM (Q1 Under Review)**
✅ **Unprecedented Accuracy**: Outperformed video-based methods using single-frame input
✅ **Novel Framework**: First unified distribution space for anatomical/textual/visual features

https://github.com/user-attachments/assets/ced85a08-e4d1-4b47-9f57-2454554d4c0a

### ⚡ **Connection-Aware Graph Convolution Networks**

`Anatomical/Kinematic Modeling`  `Multi-Level Aggregation`
✅ **HCIS Journal (Q1 Under Review)**
✅ **40% Faster** than video-based approaches while maintaining SOTA accuracy

---

## 🏆 Recognitions

`National Encouragement Scholarship 2020-2022 (Top 10%)`
`4 SCI Q1 Papers (First-Author, Under Review)`
`GPA 3.5+ @ Project 985 universities`

---

## ⚙️ Technical Arsenal

**GenAI:**       Diffusion  | DiT | VAE | RLHF | Controllable Generation
**3D Vision:**         Motion Synthesis | Pose Estimation | Occlusion Handling
**Multimodal:**    Feature Alignment | Cross-Attention | Medical Imaging
**Optimization:** KV Caching | Training Stabilization | Parametric Tuning

## 🔮 Next Mission

Pursuing opportunities to revolutionize **human-AI interaction** through:
✨ Embodied AI agents with natural motion
✨ Medical applications of generative pose systems
✨ Real-time controllable generation architectures

[](mailto:your@email.com)
[](https://github.com/yourusername)
