---
permalink: /
title: "Profile"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
 Hello, I'm Tengfei Li ğŸ‘‹ ( AKA. tfcoder âŒ¨ï¸)
`23 y/o` | `Master of AI @ Sichuan University` | ğŸ“§ `tfcoder@qq.com` | ğŸ“± `15516991101`

ğŸŒ *Building the future of human-centric AI with multimodal intelligence*

---

## ğŸ¯ Research Focus

My core research agenda centers on **human-centric artificial intelligence**, with specialized expertise in:

ğŸ•´ï¸ **Human Pose Estimation**:  `3D Reconstruction`  `Occlusion Handling`   `MultiModel Methods`

ğŸ’ƒ **Motion Synthesis & Generation**: `Interactive`  `Text-Driven Control`  `Long-Sequence Generation`

**ğŸ‘ŸVideo Motion Capture System**:

---

## ğŸš€ Key Projects & Innovations

### ğŸ’ƒ **Self-Forcing Autoregressive Diffusion for Real-Time Text-Driven Motion Generation**

`AutoRegress Diffusion`  `DiT`   `Reinforcement Learning (PPO)`  `Real-time Control`
âœ… **SOTA Performance**: Achieved 300+ FPS with KV Cache acceleration
âœ… **Breakthrough**: Enabled continuous long-sequence generation via novel self-forcing paradigm
âœ… **Optimized**: Balanced quality/speed via noise scheduling & annealing strategies

https://github.com/user-attachments/assets/f8614513-d844-493e-8da8-54cf536d6116

<video controls width='100%'>
  <source src="../assets/videos/MoGenRT_480p.mp4" type="video/mp4">
</video>

<video controls width='100%'>
  <source src="https://github.com/user-attachments/assets/f8614513-d844-493e-8da8-54cf536d6116" type="video/mp4">
</video>

<video controls width='100%'>
  <source src="https://github.com/LTF-coding/LTF-coding.github.io/blob/master/assets/videos/MoGenRT_480p.mp4" type="video/mp4">
</video>

<video controls width='100%'>
  <source src="https://LTF-coding.github.io/blob/master/assets/videos/MoGenRT_480p.mp4" type="video/mp4">
</video>


<iframe src="https://youtu.be/embed/x-4q5u8g0qA" frameborder="0"></iframe> 

### ğŸŒ **MetaPose: Multimodal Enhancement and Transformation Alignment 3D Pose Estimation**

`Vision-Text-Spatial Fusion`  `Cross-Modal Alignment` ` Occlusion Robustness`
âœ… **IEEE TMM (Q1 Under Review)**
âœ… **Unprecedented Accuracy**: Outperformed video-based methods using single-frame input
âœ… **Novel Framework**: First unified distribution space for anatomical/textual/visual features

https://github.com/user-attachments/assets/ced85a08-e4d1-4b47-9f57-2454554d4c0a

### âš¡ **Connection-Aware Graph Convolution Networks**

`Anatomical/Kinematic Modeling`  `Multi-Level Aggregation`
âœ… **HCIS Journal (Q1 Under Review)**
âœ… **40% Faster** than video-based approaches while maintaining SOTA accuracy

---

## ğŸ† Recognitions

`National Encouragement Scholarship 2020-2022 (Top 10%)`
`4 SCI Q1 Papers (First-Author, Under Review)`
`GPA 3.5+ @ Project 985 universities`

---

## âš™ï¸ Technical Arsenal

**GenAI:**       Diffusion  | DiT | VAE | RLHF | Controllable Generation
**3D Vision:**         Motion Synthesis | Pose Estimation | Occlusion Handling
**Multimodal:**    Feature Alignment | Cross-Attention | Medical Imaging
**Optimization:** KV Caching | Training Stabilization | Parametric Tuning

## ğŸ”® Next Mission

Pursuing opportunities to revolutionize **human-AI interaction** through:
âœ¨ Embodied AI agents with natural motion
âœ¨ Medical applications of generative pose systems
âœ¨ Real-time controllable generation architectures

[](mailto:your@email.com)
[](https://github.com/yourusername)
